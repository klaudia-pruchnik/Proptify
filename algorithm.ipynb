{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3ZO8+kNrlIqzlWGZyKAZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klaudia-pruchnik/Proptify/blob/main/algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYYIRp_85fXB",
        "outputId": "3d1f1914-6f5b-4dce-8773-a72bf9352d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "ln: failed to create symbolic link './mydrive/My Drive': File exists\n",
            "/content/gdrive/MyDrive/projekt_inzynierski\n"
          ]
        }
      ],
      "source": [
        "%cd /\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/ ./mydrive\n",
        "\n",
        "%cd /content/gdrive/MyDrive/projekt_inzynierski"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q\n",
        "!pip install -q faiss-cpu sentence-transformers\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download pl_core_news_sm\n",
        "!pip install gliner\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download pl_core_news_lg\n",
        "!pip install spacy gliner transformers torch"
      ],
      "metadata": {
        "id": "Zq-ziVgj8E6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from collections import defaultdict\n",
        "from math import log\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "from gliner import GLiNER\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.util import filter_spans"
      ],
      "metadata": {
        "id": "DQse5F7w8L1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modele"
      ],
      "metadata": {
        "id": "8FIs9QuWDDHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_e5 = SentenceTransformer('intfloat/multilingual-e5-base', device=device)\n",
        "model_gliner = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\n",
        "nlp_pl = spacy.load(\"pl_core_news_lg\")\n",
        "nlp_en = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "qzTwMJr28XgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframy"
      ],
      "metadata": {
        "id": "ENUAXp8JC9jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_songs = pd.read_parquet(\"./df_full_with_embeddings.parquet\")"
      ],
      "metadata": {
        "id": "4abASNdP8MMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tag_embeddings = pd.read_parquet(\"df_unique_tag_embeddings.parquet\")\n",
        "df_tag_embeddings"
      ],
      "metadata": {
        "id": "13iMKNQ6_pfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddingi tagów"
      ],
      "metadata": {
        "id": "ukFzSY_Y_97_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_VECS = np.array(df_tag_embeddings[\"tag_embedding\"].to_list(), dtype=np.float32)\n",
        "TAGS = df_tag_embeddings[\"tag\"].tolist()"
      ],
      "metadata": {
        "id": "8itmzZRf_0rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation dodatkowe"
      ],
      "metadata": {
        "id": "RCUn11K1F3mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zamień tag_list na listę"
      ],
      "metadata": {
        "id": "vceTw4hU_6g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _ensure_list(x):\n",
        "    if isinstance(x, list): return x\n",
        "    if pd.isna(x) or x is None: return []\n",
        "    return [t.strip() for t in str(x).split(\",\") if t.strip()]\n",
        "\n",
        "df_songs[\"tags_list\"] = df_songs[\"tags\"].apply(_ensure_list)\n",
        "df_songs[\"tag_count\"] = df_songs[\"tags_list\"].apply(len)\n",
        "df_songs.head(5)"
      ],
      "metadata": {
        "id": "ZHoj_ud6_5TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uzupełnij tagi ich tagami nadrzędnymi dla lepszego dopasowania (to trzeba przenieść do innego pliku i poprawić bazę)"
      ],
      "metadata": {
        "id": "AWrwINu2DHeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reguły: subgatunek -> nadrzędny\n",
        "ALSO_ADD_PARENT = {\n",
        "    # rock\n",
        "    \"progressive rock\": \"rock\",\n",
        "    \"classic rock\": \"rock\",\n",
        "    \"indie rock\": \"rock\",\n",
        "    \"hard rock\": \"rock\",\n",
        "    \"pop rock\": \"rock\",\n",
        "    \"psychedelic rock\": \"rock\",\n",
        "    \"punk rock\": \"rock\",\n",
        "    \"blues rock\": \"rock\",\n",
        "    \"post rock\": \"rock\",\n",
        "\n",
        "    # metal\n",
        "    \"heavy metal\": \"metal\",\n",
        "    \"death metal\": \"metal\",\n",
        "    \"black metal\": \"metal\",\n",
        "    \"doom metal\": \"metal\",\n",
        "    \"thrash metal\": \"metal\",\n",
        "    \"melodic death metal\": \"metal\",\n",
        "    \"symphonic metal\": \"metal\",\n",
        "    \"gothic metal\": \"metal\",\n",
        "    \"nu metal\": \"metal\",\n",
        "    \"progressive metal\": \"metal\",\n",
        "    \"power metal\": \"metal\",\n",
        "    \"metalcore\": \"metal\",\n",
        "\n",
        "    # pop / electronic\n",
        "    \"indie pop\": \"pop\",\n",
        "    \"synthpop\": \"pop\",\n",
        "    \"drum and bass\": \"electronic\",\n",
        "}\n",
        "\n",
        "# 2) reguły: słowa-klucze → nadrzędny\n",
        "PARENT_KEYWORDS = {\n",
        "    \"rock\": [\"rock\"],\n",
        "    \"metal\": [\"metal\"],\n",
        "    \"pop\": [\"pop\", \"britpop\"],\n",
        "    \"hip hop\": [\"hip hop\", \"rap\"],\n",
        "    \"electronic\": [\"electronic\", \"techno\", \"house\", \"trance\", \"idm\", \"downtempo\", \"electro\", \"ambient\"],\n",
        "    \"jazz\": [\"jazz\"],\n",
        "    \"classical\": [\"classical\"],\n",
        "    \"punk\": [\"punk\"],\n",
        "    \"folk\": [\"folk\"],\n",
        "    \"blues\": [\"blues\"],\n",
        "    \"country\": [\"country\"],\n",
        "    \"reggae\": [\"reggae\"],\n",
        "}\n",
        "\n",
        "def expand_tags(tag_list):\n",
        "    if tag_list is None or (isinstance(tag_list, float) and pd.isna(tag_list)):\n",
        "        tag_list = []\n",
        "\n",
        "    # normalizacja minimalna: małe litery, zamiana _ → spacja\n",
        "    tags = {str(t).lower().replace(\"_\", \" \").strip() for t in tag_list}\n",
        "\n",
        "    # 1) subgatunek → nadrzędny\n",
        "    for child, parent in ALSO_ADD_PARENT.items():\n",
        "        if child in tags:\n",
        "            tags.add(parent)\n",
        "\n",
        "    # 2) słowa kluczowe → nadrzędny\n",
        "    for parent, kws in PARENT_KEYWORDS.items():\n",
        "        if any(kw in t for t in tags for kw in kws):\n",
        "            tags.add(parent)\n",
        "\n",
        "    return sorted(tags)\n",
        "\n",
        "# zastosowanie\n",
        "df_songs[\"tags_list\"] = df_songs[\"tags_list\"].apply(expand_tags)\n"
      ],
      "metadata": {
        "id": "3T8UXhKkDII3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_songs[\"tags_list\"] = df_songs[\"tags_list\"].apply(\n",
        "    lambda lst: [tag.replace(\"_\", \" \") for tag in lst]\n",
        ")"
      ],
      "metadata": {
        "id": "jU0vE0RoH18I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorytm dopasowania utworów"
      ],
      "metadata": {
        "id": "5R6dvTBwF8NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Budowanie inverted index do późniejszego scorowania utworów"
      ],
      "metadata": {
        "id": "eBpMlIqZFlrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_songs = df_songs.reset_index(drop=True)\n",
        "\n",
        "def build_inverted_index(df_songs: pd.DataFrame, tags_col: str = \"tags_list\"):\n",
        "    inv = defaultdict(list)\n",
        "    df_count = defaultdict(int)  # document frequency: w ilu utworach wystąpił tag\n",
        "\n",
        "    for i, tags in enumerate(df_songs[tags_col]):\n",
        "        if not tags:\n",
        "            continue\n",
        "        seen = set()\n",
        "        for t in tags:\n",
        "            inv[t].append(i)\n",
        "            if t not in seen:\n",
        "                df_count[t] += 1\n",
        "                seen.add(t)\n",
        "\n",
        "    # zamieniamy listy na numpy dla szybkości\n",
        "    for t in inv:\n",
        "        inv[t] = np.asarray(inv[t], dtype=np.int32)\n",
        "\n",
        "    return inv, df_count\n",
        "\n",
        "INV_INDEX, DF_COUNT = build_inverted_index(df_songs, tags_col=\"tags_list\")\n",
        "N_SONGS = len(df_songs)\n",
        "AVG_TAG_LEN = float(df_songs[\"tag_count\"].mean()) if \"tag_count\" in df_songs else 10.0"
      ],
      "metadata": {
        "id": "BaOQA0AUFeXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config do wszystkich parametrów algorytmu"
      ],
      "metadata": {
        "id": "69s9s8O0HWRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RETRIEVAL_CONFIG = {\n",
        "    \"n_candidates\": 200,    # początkowe top najlepiej dopasowanych wg FAISS\n",
        "}\n",
        "\n",
        "SCORE_TIERS_CONFIG = {\n",
        "    \"t_high\": 0.9,\n",
        "    \"t_mid\": 0.7,\n",
        "    \"min_final\": 100,         # chcemy finalnie tyle\n",
        "    \"max_c_from_low_tier\": 15,  # ile max brać z Tier C gdy brakuje\n",
        "}\n",
        "\n",
        "POPULARITY_CONFIG = {\n",
        "    \"p_high\": 70,\n",
        "    \"p_mid\": 35,\n",
        "    # procentowy miks w finalnym secie (docelowy)\n",
        "    \"mix\": {\n",
        "        \"high\": 0.4,     # popularne\n",
        "        \"mid\": 0.35,     # średnie\n",
        "        \"low\": 0.25,     # niszowe\n",
        "    },\n",
        "    \"forced_popular\": 2,    # ile utworów bardzo popularnych wstawić na sztywno\n",
        "    \"forced_popular_min\": 80,\n",
        "}\n",
        "\n",
        "SAMPLING_CONFIG = {\n",
        "    \"final_n\": 15,\n",
        "    \"alpha\": 2.0,   # jak mocno faworyzujemy wyższy score przy losowaniu\n",
        "}\n",
        "\n",
        "QUERY_TAGS_CONFIG = {\n",
        "    \"rel_keep\": 0.98,   # próg względny: bierzemy tagi >= 70% najlepszego\n",
        "    \"abs_keep\": 0.9,  # próg absolutny: odetnij totalny szum\n",
        "    \"min_keep\": 1,     # min liczba tagów w profilu\n",
        "    \"max_keep\": 12,    # max liczba tagów w profilu\n",
        "    \"top_m_per_ngram\": 2,\n",
        "    \"min_ngram_sim\": 0.7,\n",
        "    \"min_unigram_sim\": 0.5,\n",
        "    \"power\": 1,\n",
        "    \"include_unigrams\": True,\n",
        "}\n",
        "\n",
        "TAG_SCORING_CONFIG = {\n",
        "    \"use_idf\": False,           # waż tagi rzadkie wyżej\n",
        "    \"k1\": 1.2,                 # siła normalizacji „długości dokumentu” (liczby tagów utworu)\n",
        "    \"b\": 0.75,\n",
        "    \"len_norm\": False,\n",
        "    \"query_pow\": 1.0,          # możesz podnieść np. 1.2 by ostrzej różnicować wagi tagów z promptu\n",
        "    \"normalize_by_tags\": False # alternatywna, prostsza normalizacja: score / sqrt(n_tags_utworu)\n",
        "}\n"
      ],
      "metadata": {
        "id": "C7GQZtclH-Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyciągamy podzielone, oczyszczone wyrażenia z propta usera"
      ],
      "metadata": {
        "id": "sm9z3LGrKCfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "GDMOIL7noieM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect, DetectorFactory"
      ],
      "metadata": {
        "id": "-PWgrZD7og9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ustawiamy ziarno dla detekcji języka (żeby wyniki były powtarzalne dla krótkich tekstów)\n",
        "DetectorFactory.seed = 0"
      ],
      "metadata": {
        "id": "IvdEPlNZoqqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy: Model do parsowania gramatycznego i Matchera (zapewnia precyzyjne wzorce)\n",
        "nlp_pl = spacy.load(\"pl_core_news_lg\")\n",
        "nlp_en = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "-9Eu4I_fJ_F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GLINER_LABELS = [\n",
        "    \"opis_emocji\",\n",
        "    \"poziom_energii\",\n",
        "    \"opis_tempa\",\n",
        "    \"gatunek_muzyczny\",\n",
        "    \"opis_wokalu\",\n",
        "    \"przeznaczenie_utworu\",\n",
        "    \"cecha_brzmienia\",\n",
        "    \"cecha_instrumentu\"\n",
        "]\n",
        "\n",
        "GENERIC_LEMMAS = [\n",
        "    # Polski\n",
        "    \"muzyka\", \"utwór\", \"piosenka\", \"kawałek\", \"playlista\", \"lista\", \"numer\", \"rok\", \"klimat\", \"styl\",\n",
        "    # Angielski\n",
        "    \"music\", \"song\", \"track\", \"playlist\", \"list\", \"number\", \"vibe\", \"tune\", \"genre\", \"style\"\n",
        "]\n",
        "\n",
        "GENERIC_VERBS = [\n",
        "    # --- POLSKI (Bezokoliczniki / Lematy) ---\n",
        "    # Szukanie / Chcenie\n",
        "    \"szukać\", \"poszukiwać\", \"chcieć\", \"pragnąć\", \"potrzebować\", \"woleć\", \"wymagać\",\n",
        "    # Bycie / Posiadanie\n",
        "    \"być\", \"mieć\", \"znajdować\", \"znaleźć\",\n",
        "    # Słuchanie / Odtwarzanie\n",
        "    \"słuchać\", \"posłuchać\", \"usłyszeć\", \"grać\", \"zagrać\", \"puszczać\", \"puścić\", \"odtworzyć\", \"zapodać\",\n",
        "    # Prośby / Rekomendacje\n",
        "    \"prosić\", \"polecić\", \"polecać\", \"rekomendować\", \"sugerować\", \"zaproponować\", \"dawać\", \"dać\",\n",
        "\n",
        "    # --- ANGIELSKI (Base forms) ---\n",
        "    # Searching / Wanting\n",
        "    \"search\", \"look\", \"find\", \"want\", \"need\", \"desire\", \"wish\", \"require\",\n",
        "    # Being / Having\n",
        "    \"be\", \"have\", \"get\",\n",
        "    # Listening / Playing\n",
        "    \"listen\", \"hear\", \"play\", \"replay\", \"stream\",\n",
        "    # Requests\n",
        "    \"give\", \"recommend\", \"suggest\", \"show\", \"provide\",\n",
        "]\n",
        "\n",
        "NEGATION_TERMS = [\n",
        "    # PL\n",
        "    \"nie\", \"bez\", \"mało\", \"zero\", \"ani\", \"żaden\", \"brak\", \"mniej\",\n",
        "    # EN\n",
        "    \"no\", \"not\", \"without\", \"less\", \"non\", \"neither\", \"nor\", \"lack\", \"zero\"\n",
        "]"
      ],
      "metadata": {
        "id": "2SLtO0jO3zBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_matcher_for_nlp(nlp_instance):\n",
        "    \"\"\"Tworzy obiekt Matcher przypisany do konkretnego modelu językowego\"\"\"\n",
        "    matcher = Matcher(nlp_instance.vocab)\n",
        "\n",
        "    # Warunek wykluczający\n",
        "    # To musi być Rzeczownik, ale NIE MOŻE być na liście generycznej\n",
        "    noun_filter = {\n",
        "        \"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]},\n",
        "        \"IS_STOP\": False,\n",
        "        \"LEMMA\": {\"NOT_IN\": GENERIC_LEMMAS}\n",
        "    }\n",
        "\n",
        "    matcher.add(\"FRAZA\", [\n",
        "        # 1. Samodzielne NOUN/PROPN (rock)\n",
        "        [noun_filter],\n",
        "        # 2. ADJ + NOUN (szybki bas)\n",
        "        [{\"POS\": \"ADJ\"}, noun_filter],\n",
        "        # 3. (ADV)? + ADP + NOUN (z tańca, z klimatem -> filtrowane)\n",
        "        [{\"POS\": \"ADV\", \"OP\": \"?\"}, {\"POS\": \"ADP\"}, noun_filter],\n",
        "        # 4. ADV + ADJ (bardzo wesoła)\n",
        "        [{\"POS\": \"ADV\"}, {\"POS\": \"ADJ\", \"IS_STOP\": False}],\n",
        "        # 5. ADJ Samotny (rockowa)\n",
        "        [{\"POS\": \"ADJ\", \"IS_STOP\": False}],\n",
        "        # 6. Złożone Rzeczowniki (post rock)\n",
        "        [{\"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}, \"IS_STOP\": False}, noun_filter],\n",
        "        # 7. Złożona relacja (dobra do tańca)\n",
        "        [{\"POS\": \"ADV\", \"OP\": \"?\"}, {\"POS\": \"ADJ\"}, {\"POS\": \"ADP\"}, noun_filter],\n",
        "        # 8. Celuje w: Czasownik opisowy + Rzeczownik/Adjektive/Zaimek\n",
        "        [\n",
        "            {\"POS\": \"VERB\", \"LEMMA\": {\"NOT_IN\": GENERIC_VERBS}},\n",
        "            {\"POS\": {\"IN\": [\"NOUN\", \"ADJ\", \"PRON\"]}, \"OP\": \"+\"} # Obiekt czasownika (może być więcej niż jedno słowo)\n",
        "        ]\n",
        "    ])\n",
        "    return matcher\n",
        "\n",
        "# Tworzymy matchery raz na starcie\n",
        "matcher_pl = create_matcher_for_nlp(nlp_pl)\n",
        "matcher_en = create_matcher_for_nlp(nlp_en)\n"
      ],
      "metadata": {
        "id": "JiltEBBzuDJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. FUNKCJA POMOCNICZA: SPRAWDZANIE NEGACJI\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def is_span_negated(doc, start_index, window=2):\n",
        "    \"\"\"\n",
        "    Sprawdza, czy przed frazą (start_index) stoi słowo przeczące.\n",
        "    Patrzy 'window' tokenów wstecz.\n",
        "    \"\"\"\n",
        "    lookback = max(0, start_index - window)\n",
        "    preceding_tokens = doc[lookback:start_index]\n",
        "\n",
        "    for token in preceding_tokens:\n",
        "        if token.text.lower() in NEGATION_TERMS:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "5eAqNyz-Ap0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# 3. GŁÓWNA FUNKCJA HYBRYDOWA: EKSTRAKCJA FRAZ\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def extract_relevant_phrases(prompt):\n",
        "    \"\"\"\n",
        "    Łączy GLiNER i Matcher w celu wydobycia istotnych, niepowtarzających się fraz\n",
        "    opisujących cechy muzyczne z promptu.\n",
        "    \"\"\"\n",
        "    prompt = prompt.lower()\n",
        "\n",
        "    try:\n",
        "        lang_code = detect(prompt)\n",
        "    except:\n",
        "        lang_code = 'pl'\n",
        "\n",
        "    # Wybór odpowiedniego zestawu narzędzi\n",
        "    if lang_code == 'en':\n",
        "        current_nlp = nlp_en\n",
        "        current_matcher = matcher_en\n",
        "        lang_msg = \"EN\"\n",
        "    else:\n",
        "        current_nlp = nlp_pl\n",
        "        current_matcher = matcher_pl\n",
        "        lang_msg = \"PL\"\n",
        "\n",
        "    # Przetwarzanie wybranym modelem\n",
        "    doc = current_nlp(prompt)\n",
        "\n",
        "    # 1. EKSTRAKCJA Z GLINER (Łapie kontekst, długie frazy, np. \"muzyka, która jest smutna\")\n",
        "    # Niska wartość threshold jest celowa, aby złapać więcej kandydatów.\n",
        "    gliner_entities = model_gliner.predict_entities(prompt, GLINER_LABELS, threshold=0.1)\n",
        "    gliner_phrases_raw = [e['text'].lower() for e in gliner_entities]\n",
        "\n",
        "    # 2. EKSTRAKCJA Z MATCHER (Łapie pojedyncze rzeczowniki i precyzyjne wzorce)\n",
        "    matcher_matches = current_matcher(doc)\n",
        "    matcher_spans = [doc[start:end] for match_id, start, end in matcher_matches]\n",
        "\n",
        "    # filter_spans wybiera najdłuższe, nie nakładające się frazy Matchera\n",
        "    combined_spans = filter_spans(matcher_spans)\n",
        "    matcher_phrases = [span.text.lower() for span in combined_spans]\n",
        "\n",
        "    # 3. FILTRACJA WYNIKÓW GLINER\n",
        "    filtered_gliner_phrases = []\n",
        "\n",
        "    for phrase in gliner_phrases_raw:\n",
        "        phrase_doc = current_nlp(phrase)\n",
        "        is_generic_noise = False\n",
        "\n",
        "        # Sprawdzenie lematu GŁÓWNEGO słowa w frazie GLINERa\n",
        "        for token in phrase_doc:\n",
        "            if token.pos_ in [\"NOUN\", \"PROPN\"] and token.lemma_.lower() in GENERIC_LEMMAS:\n",
        "                # Jeśli fraza zawiera generyczny rzeczownik, traktujemy ją jako szum\n",
        "                is_generic_noise = True\n",
        "                break\n",
        "\n",
        "        if not is_generic_noise:\n",
        "            filtered_gliner_phrases.append(phrase)\n",
        "\n",
        "    # 4. Fuzja wyników\n",
        "    all_phrases = filtered_gliner_phrases + matcher_phrases\n",
        "    unique_phrases = sorted(list(set([p.strip() for p in all_phrases if len(p.strip()) > 1])))\n",
        "\n",
        "    print(f'Matcher only: {matcher_phrases}')\n",
        "    print(f'Gliner only: {filtered_gliner_phrases}')\n",
        "    print(f\"[{lang_msg}] Prompt: '{prompt}' \\n-> {unique_phrases}\")\n",
        "\n",
        "    return unique_phrases"
      ],
      "metadata": {
        "id": "BmHg6GWmtVvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# 4. PRZYKŁADY UŻYCIA\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "TEST_PROMPT_1 = \"szukam muzyki rockowej, ale takiej pełnej spokoju i bardzo wesołej, trochę do tańca\"\n",
        "TEST_PROMPT_2 = \"rock, pop, dance i coś do tańca, zależy mi na maksymalnej energii\"\n",
        "TEST_PROMPT_3 = \"rock, pop, dance i coś do tańca, zależy mi na maksymalnej energii, post rock, alternative rock, rock alternatywny, pop\"\n",
        "TEST_PROMPT_4 = \"muzyka rockowa z lat 90, z klimatem podróży, postpankowa\"\n",
        "TEST_PROMPT_5 = \"muzyka bez słów, smutna, nostalgiczna, spokojna\"\n",
        "TEST_PROMPT_6 = \"szybka, intensywna, bardzo dobra do tańca, zabawy, zajsta do tańca, idealna do tańca, \"\n",
        "TEST_PROMPT_7 = \"albo zwykły rock, albo jakiś post rock albo punk, coś takiego\"\n",
        "TEST_PROMPT_8 = \"muzyka dynamiczna, szybko, szybkie tempo, wysokie tempo, energiczna\"\n",
        "TEST_PROMPT_9 = \"muzyka, która koi nerwy\"\n",
        "TEST_PROMPT_10 = \"muzyka, która koi nerwy\"\n",
        "TEST_PROMPT_11 = \"Szukam muzyki rockowej, ale nie smutnej\"\n",
        "TEST_PROMPT_12 = \"I want energetic songs, no slow music\"\n",
        "\n",
        "relevant_phrases = extract_relevant_phrases(TEST_PROMPT_12)"
      ],
      "metadata": {
        "id": "a_MvQBkaKA_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvQSenUT56oo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}